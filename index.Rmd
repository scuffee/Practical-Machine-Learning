---
title: "Practical-Machine-Learning"
author: "Sandra Cuffee"
date: December 7, 2017
output: html_document
---


```{r setup, include=FALSE}
library(dplyr);library(utils);library(caret);library(doParallel);library(ggplot2);library(parallel);library(stats)
knitr::opts_chunk$set(echo = TRUE)
```


## **Note:**

devtools::install_github('topepo/caret/pkg/caret') , was required for parallel processing of data file.

My project can be viewed at:

http://scuffee.github.io/Practical-Machine-Learning/index.html


## **Summary**

A training and testing data set were used to predict to quantify how six participants performed five exercises.  The training data was cleaned, 53 of the 160 variables along with 9812 of 19622 oberservation were used as a basis for the predictions.  Twenty observations with 160 variables were use to predict how well the exercises were done. The training data indicated classe A, performing the bicep curls according to specification; followed by classe B, throwing the elbows to the front; classe E, throwing the  hips to the front was third; classe C fourth, lifting the dumbell halfway; and classe D, lowering the dumbell halfway.  using random forest regression he training data accuracy was 99.49% with an oob error rate of .4%, The test data proability prediction matched the training data results as shown in the histogram and bloxplot in the appendix.




## **Data Files**

The data files were retrieved from: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

```{r, echo = FALSE}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="pml-training.csv",method="libcurl")

download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfile="pml-testing.csv",method="libcurl")
```

## **The Data**

Two data frames were created in order to explore, run tests, and generate graphs pertaining to the training and test data.  The training data frame was used to create the training data set.  The testing data frame was used for the test data set. 


```{r, echo= FALSE}

training<-(read.csv("pml-training.csv",header=TRUE,sep=","))
testing<-(read.csv("pml-testing.csv",header=TRUE, sep=","))
```

## **Information About the Training and Test Data**

"Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).( Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H., 2013)"  The training data frame consisted of 19,622 observations and 160 variables.  The test data set consisted of 20 observations and 160 variables.

### Observations and Predictors

```{r, library(dplyr), library(utils), library(caret), library(doParallel), library(parallel), library(ggplot2), echo =FALSE}

glimpse(training) #print variable names and types
sum(is.na(training)) #check for missing data

```

###  Cleaning the Training Data 

The training data frame was reviewed in table format using fix() and glimpse() to help determine what data would be useful for testing the training data.  The glimpse function was used to verify the predictor variables under test.  The training data set was reduced to 53 variables.  No changes were made to the test data.

```{r, echo=FALSE}

nv<-nearZeroVar(training,saveMetrics=TRUE,names = TRUE) # ID Predictors to Remove
training=training[,c(-6,-12:-17,-20,-26,-51:-59,-69:-75,-78,-79,-81,-82,-87:-92,-95,-98,-101,-125:-131,-133,-134,-139,-142:-150)]
##fix(training)
training = training[,c(-11:-25)]
##fix(training)
training = training[,c(-1:-5,-11, -12, -26,-36:-39,-43:-48,-50:-59,-72:-76,-78)]
##fix(training)
sum(is.na(training));glimpse(training)

```

## **Random Forest Analysis on Training Data Set**

Random forest tests were conducted using the caret function for accuracy and parallel processing was used to reduce the run time of the tests on the training data set. The mtry equal to 27 provided the best results for the training data set.  The accuracy was 99.49% and oob error rate was .4% as indicated in the cross validation test conducted.

```{r, echo=FALSE}
library(caret);library(doParallel);library(parallel)
set.seed(97544)
 inTrain <- createDataPartition(training$classe,list=FALSE)
 trainingTrain<-training[inTrain,]
 testTrain<-training[-inTrain,]
 y <- trainingTrain[,54]
 x <- trainingTrain[,-54]
 cluster <- makeCluster(detectCores() - 1)
 registerDoParallel(cluster)
 fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
 fit <- train(x,y, method="rf",data=training,trControl = fitControl)
 stopCluster(cluster)
 registerDoSEQ()
 
```

### Predictions with the Test Data
The test data consisted of 20 observations and 160 predictors.  Since the trainingSet was the basis for the test data, 53 predictors were used. The initial prediction of the test data was the raw data and the second prediction consisted of the probabilities. the raw data output showed what classe level would be predicted and the probability output showed how likely the particular classe would be picked.  

```{r, fit, echo=FALSE}

testSet<-predict(fit,testing,type="raw")
testSet1<-predict(fit,testing,type="prob")

```

### Prediction Results

Statistical analysis was completed for the training and test data sets. traingSet represented the training data, testSet represented the raw prediction test data and tesSet1 represented the probbility test data. The training data was resampled and cross validated for accuracy.  The trainingset accuracy was cross-validated with an accuracy rate of 99.49% when the optimal mtry was 27.  The cross-validation results also indicated classe A had the higest prediction of 28.4, classe B was second at 19.2, classe E third at 18.3, classe C fourth at 17.3, and classe D had the lowest prediction of 16.2 The out oob error rate was .4%.  The testSet raw data indicated classe A  and B had a  prediction frequency of 7, followed by 4 for classe B, classe C and D were tied at 1 each.  the test data prediction supports the training data results. 

```{r, echo=FALSE}
fit
fit$resample
confusionMatrix.train(fit)
fit$finalModel
trainingSet<-(fit$finalModel)
print(trainingSet)

print(testSet);print(testSet1)

```

## **Plots**

A diagnostic plot was created for the trainingSet. A histogram showing number of times each level was predicted and a boxplot of the probability of each level predicted.  The histogram showl classe A was the most frequently predicted follow bt classe B.  the boxplot indicates classe A had the higest prediction probability, followed by classe.  Classe C, D, and E had low frequency counts and low probibilitie of being predicted. 

###  Training Set Diagnostics
```{r, library(ggplot2), echo=FALSE}


plot(trainingSet,pch=19,cex=0.5,col="red")
```

### Frequency of Test Predicition Levels

```{r, echo=FALSE}

plot(testSet)
```

### Probablity of Each Level

```{r, echo = FALSE}

boxplot(testSet1,col="blue")
```

## **Appendix**

### References 

gh-page setup

https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-ghPagesSetup.md


Improving Peformance of Random Forest in caret::train()

https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md


Practical Machine Learning Project

http://scuffee.github.io/Practical-Machine-Learning/index.html


Weight Lifting Exercises Dataset

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013

. 
